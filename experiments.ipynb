{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109e0166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version  : 2.9.0.dev20250715\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt\n",
    "import importlib\n",
    "importlib.reload\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import torch, os, sys\n",
    "print(\"torch version  :\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4788 patterns of size 32*32 → data/train_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "!python scripts/convert_dm4.py --input data/Diffraction_SI.dm4 --output data/train_tensor.h5 --downsample 16 --mode bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee54b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Seed set to 42\n",
      "Detected input size: 32x32\n",
      "/Users/louisg/.pyenv/versions/custom_ae/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Layer                              Input → Output                    Params\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "000_model_encoder_conv_input_Conv2d(1, 1, 32, 32) → (1, 64, 32, 32)       640\n",
      "001_model_encoder_bn_input_BatchNorm2d(1, 64, 32, 32) → (1, 64, 32, 32)       128\n",
      "002_model_encoder_conv_pre_Conv2d  (1, 64, 32, 32) → (1, 128, 32, 32)    73,856\n",
      "003_model_encoder_bn_pre_BatchNorm2d(1, 128, 32, 32) → (1, 128, 32, 32)       256\n",
      "004_model_encoder_resnet1_conv_block_conv1_Conv2d(1, 128, 32, 32) → (1, 128, 32, 32)   147,584\n",
      "005_model_encoder_resnet1_conv_block_bn1_BatchNorm2d(1, 128, 32, 32) → (1, 128, 32, 32)       256\n",
      "006_model_encoder_resnet1_conv_block_conv2_Conv2d(1, 128, 32, 32) → (1, 128, 32, 32)   147,584\n",
      "007_model_encoder_resnet1_conv_block_bn2_BatchNorm2d(1, 128, 32, 32) → (1, 128, 32, 32)       256\n",
      "008_model_encoder_resnet1_conv_block_conv3_Conv2d(1, 128, 32, 32) → (1, 128, 32, 32)   147,584\n",
      "009_model_encoder_resnet1_conv_block_bn3_BatchNorm2d(1, 128, 32, 32) → (1, 128, 32, 32)       256\n",
      "010_model_encoder_resnet1_identity_block_conv_Conv2d(1, 128, 32, 32) → (1, 128, 32, 32)   147,584\n",
      "011_model_encoder_resnet1_identity_block_bn_BatchNorm2d(1, 128, 32, 32) → (1, 128, 32, 32)       256\n",
      "012_model_encoder_resnet2_conv_block_conv1_Conv2d(1, 128, 8, 8) → (1, 128, 8, 8)   147,584\n",
      "013_model_encoder_resnet2_conv_block_bn1_BatchNorm2d(1, 128, 8, 8) → (1, 128, 8, 8)       256\n",
      "014_model_encoder_resnet2_conv_block_conv2_Conv2d(1, 128, 8, 8) → (1, 128, 8, 8)   147,584\n",
      "015_model_encoder_resnet2_conv_block_bn2_BatchNorm2d(1, 128, 8, 8) → (1, 128, 8, 8)       256\n",
      "016_model_encoder_resnet2_conv_block_conv3_Conv2d(1, 128, 8, 8) → (1, 128, 8, 8)   147,584\n",
      "017_model_encoder_resnet2_conv_block_bn3_BatchNorm2d(1, 128, 8, 8) → (1, 128, 8, 8)       256\n",
      "018_model_encoder_resnet2_identity_block_conv_Conv2d(1, 128, 8, 8) → (1, 128, 8, 8)   147,584\n",
      "019_model_encoder_resnet2_identity_block_bn_BatchNorm2d(1, 128, 8, 8) → (1, 128, 8, 8)       256\n",
      "020_model_encoder_resnet3_conv_block_conv1_Conv2d(1, 128, 2, 2) → (1, 128, 2, 2)   147,584\n",
      "021_model_encoder_resnet3_conv_block_bn1_BatchNorm2d(1, 128, 2, 2) → (1, 128, 2, 2)       256\n",
      "022_model_encoder_resnet3_conv_block_conv2_Conv2d(1, 128, 2, 2) → (1, 128, 2, 2)   147,584\n",
      "023_model_encoder_resnet3_conv_block_bn2_BatchNorm2d(1, 128, 2, 2) → (1, 128, 2, 2)       256\n",
      "024_model_encoder_resnet3_conv_block_conv3_Conv2d(1, 128, 2, 2) → (1, 128, 2, 2)   147,584\n",
      "025_model_encoder_resnet3_conv_block_bn3_BatchNorm2d(1, 128, 2, 2) → (1, 128, 2, 2)       256\n",
      "026_model_encoder_resnet3_identity_block_conv_Conv2d(1, 128, 2, 2) → (1, 128, 2, 2)   147,584\n",
      "027_model_encoder_resnet3_identity_block_bn_BatchNorm2d(1, 128, 2, 2) → (1, 128, 2, 2)       256\n",
      "028_model_encoder_conv_post_Conv2d (1, 128, 1, 1) → (1, 64, 1, 1)    73,792\n",
      "029_model_encoder_conv_final_Conv2d(1, 64, 1, 1) → (1, 1, 1, 1)         577\n",
      "030_model_encoder_embedding_linear_Linear(1, 16) → (1, 8)                     136\n",
      "031_model_decoder_decoder_linear_Linear(1, 8) → (1, 2048)                18,432\n",
      "032_model_decoder_decoder_conv_initial_Conv2d(1, 128, 4, 4) → (1, 128, 4, 4)   147,584\n",
      "033_model_decoder_decoder_resnet_up1_conv_block_conv1_Conv2d(1, 128, 16, 16) → (1, 128, 16, 16)   147,584\n",
      "034_model_decoder_decoder_resnet_up1_conv_block_bn1_BatchNorm2d(1, 128, 16, 16) → (1, 128, 16, 16)       256\n",
      "035_model_decoder_decoder_resnet_up1_conv_block_conv2_Conv2d(1, 128, 16, 16) → (1, 128, 16, 16)   147,584\n",
      "036_model_decoder_decoder_resnet_up1_conv_block_bn2_BatchNorm2d(1, 128, 16, 16) → (1, 128, 16, 16)       256\n",
      "037_model_decoder_decoder_resnet_up1_conv_block_conv3_Conv2d(1, 128, 16, 16) → (1, 128, 16, 16)   147,584\n",
      "038_model_decoder_decoder_resnet_up1_conv_block_bn3_BatchNorm2d(1, 128, 16, 16) → (1, 128, 16, 16)       256\n",
      "039_model_decoder_decoder_resnet_up1_identity_block_conv_Conv2d(1, 128, 16, 16) → (1, 128, 16, 16)   147,584\n",
      "040_model_decoder_decoder_resnet_up1_identity_block_bn_BatchNorm2d(1, 128, 16, 16) → (1, 128, 16, 16)       256\n",
      "041_model_decoder_decoder_resnet_up2_conv_block_conv1_Conv2d(1, 128, 64, 64) → (1, 128, 64, 64)   147,584\n",
      "042_model_decoder_decoder_resnet_up2_conv_block_bn1_BatchNorm2d(1, 128, 64, 64) → (1, 128, 64, 64)       256\n",
      "043_model_decoder_decoder_resnet_up2_conv_block_conv2_Conv2d(1, 128, 64, 64) → (1, 128, 64, 64)   147,584\n",
      "044_model_decoder_decoder_resnet_up2_conv_block_bn2_BatchNorm2d(1, 128, 64, 64) → (1, 128, 64, 64)       256\n",
      "045_model_decoder_decoder_resnet_up2_conv_block_conv3_Conv2d(1, 128, 64, 64) → (1, 128, 64, 64)   147,584\n",
      "046_model_decoder_decoder_resnet_up2_conv_block_bn3_BatchNorm2d(1, 128, 64, 64) → (1, 128, 64, 64)       256\n",
      "047_model_decoder_decoder_resnet_up2_identity_block_conv_Conv2d(1, 128, 64, 64) → (1, 128, 64, 64)   147,584\n",
      "048_model_decoder_decoder_resnet_up2_identity_block_bn_BatchNorm2d(1, 128, 64, 64) → (1, 128, 64, 64)       256\n",
      "049_model_decoder_decoder_resnet_up3_conv_block_conv1_Conv2d(1, 128, 256, 256) → (1, 128, 256, 256)   147,584\n",
      "050_model_decoder_decoder_resnet_up3_conv_block_bn1_BatchNorm2d(1, 128, 256, 256) → (1, 128, 256, 256)       256\n",
      "051_model_decoder_decoder_resnet_up3_conv_block_conv2_Conv2d(1, 128, 256, 256) → (1, 128, 256, 256)   147,584\n",
      "052_model_decoder_decoder_resnet_up3_conv_block_bn2_BatchNorm2d(1, 128, 256, 256) → (1, 128, 256, 256)       256\n",
      "053_model_decoder_decoder_resnet_up3_conv_block_conv3_Conv2d(1, 128, 256, 256) → (1, 128, 256, 256)   147,584\n",
      "054_model_decoder_decoder_resnet_up3_conv_block_bn3_BatchNorm2d(1, 128, 256, 256) → (1, 128, 256, 256)       256\n",
      "055_model_decoder_decoder_resnet_up3_identity_block_conv_Conv2d(1, 128, 256, 256) → (1, 128, 256, 256)   147,584\n",
      "056_model_decoder_decoder_resnet_up3_identity_block_bn_BatchNorm2d(1, 128, 256, 256) → (1, 128, 256, 256)       256\n",
      "057_model_decoder_decoder_conv_final_Conv2d(1, 128, 256, 256) → (1, 1, 256, 256)     1,153\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Total params                                                      3,864,714\n",
      "Trainable                                                         3,864,714\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "PERFORMANCE EVALUATION\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "MSE                 0.318382 ± 0.000000\n",
      "PSNR (dB)           4.97 ± 0.00\n",
      "SSIM                -0.0069 ± 0.0000\n",
      "WARNING             High MSE - check model training\n",
      "WARNING             Low PSNR - poor reconstruction quality\n",
      "Comparison saved to outputs/reconstruction_comparison.png\n",
      "STEM visualization saved to: outputs/stem_visualization.png\n",
      "STEM visualization  outputs/stem_visualization.png\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params | Mode\n",
      "---------------------------------------------\n",
      "0 | model | Autoencoder | 3.9 M  | eval\n",
      "---------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.9 M     Total params\n",
      "15.459    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "115       Modules in eval mode\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]/Users/louisg/.pyenv/versions/custom_ae/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/louisg/.pyenv/versions/custom_ae/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/louisg/.pyenv/versions/custom_ae/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "Epoch 0: 100%|████| 120/120 [10:48<00:00,  0.19it/s, v_num=2, train_loss=0.0298]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▋                  | 1/30 [00:01<00:51,  0.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▎                 | 2/30 [00:02<00:34,  0.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▉                 | 3/30 [00:03<00:28,  0.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▌                | 4/30 [00:03<00:25,  1.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▏               | 5/30 [00:04<00:23,  1.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 6/30 [00:05<00:21,  1.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|████▍              | 7/30 [00:06<00:19,  1.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|█████              | 8/30 [00:06<00:18,  1.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 9/30 [00:07<00:17,  1.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|██████            | 10/30 [00:08<00:16,  1.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▌           | 11/30 [00:08<00:15,  1.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▏          | 12/30 [00:09<00:14,  1.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▊          | 13/30 [00:10<00:13,  1.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|████████▍         | 14/30 [00:10<00:12,  1.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 15/30 [00:11<00:11,  1.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|█████████▌        | 16/30 [00:12<00:10,  1.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|██████████▏       | 17/30 [00:13<00:10,  1.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 18/30 [00:13<00:09,  1.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|███████████▍      | 19/30 [00:14<00:08,  1.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████████      | 20/30 [00:15<00:07,  1.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 21/30 [00:15<00:06,  1.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████████▏    | 22/30 [00:16<00:06,  1.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████████▊    | 23/30 [00:17<00:05,  1.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 24/30 [00:18<00:04,  1.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|███████████████   | 25/30 [00:18<00:03,  1.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████████▌  | 26/30 [00:19<00:02,  1.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 27/30 [00:20<00:02,  1.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████████▊ | 28/30 [00:20<00:01,  1.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████████████▍| 29/30 [00:21<00:00,  1.35it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 30/30 [00:22<00:00,  1.35it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 120/120 [11:14<00:00,  0.18it/s, v_num=2, train_loss=0.0298, va\u001b[A`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 120/120 [11:14<00:00,  0.18it/s, v_num=2, train_loss=0.0298, va\n",
      "Model saved to outputs/ae.ckpt\n",
      "Loss curve saved to outputs/loss_curve.png\n",
      "\n",
      "================================================================================\n",
      "FINAL MODEL EVALUATION\n",
      "================================================================================\n",
      "Validation MSE:     0.029735 ± 0.007920\n",
      "Validation PSNR:    15.42 ± 1.15 dB\n",
      "Validation SSIM:    0.4758 ± 0.0914\n",
      "Final comparison saved to outputs/final_reconstruction_comparison.png\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.train --data data/train_tensor.pt --epochs 1 --batch 32 --latent 8 --lr 0.00003 --output_dir outputs --device mps --summary True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ba65ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading model from outputs/ae.ckpt\n",
      "Hyperparameters: {'latent_dim': 32, 'lr': 3e-05, 'realtime_metrics': False, 'lambda_act': 1e-05, 'lambda_sim': 0, 'lambda_div': 0, 'out_shape': (512, 512)}\n",
      "Model loaded successfully. Latent dim: 32\n",
      "Test output stats: mean=0.045495, std=0.091439, max=0.596971\n",
      "Loading data from data/train_tensor_ds1.pt\n",
      "Data shape: torch.Size([32, 1, 512, 512])\n",
      "Generating reconstructions...\n",
      "Evaluating reconstruction quality...\n",
      "Original non-zero pixels: 490885\n",
      "Reconstruction non-zero pixels: 8388608\n",
      "Original: mean=0.043847, std=0.176167\n",
      "Reconstruction: mean=0.045412, std=0.091239\n",
      "Reconstruction Quality Assessment: POOR\n",
      "Overall Correlation: 0.4622\n",
      "Log-space Correlation: 0.4618\n",
      "\n",
      "============================================================\n",
      "RECONSTRUCTION QUALITY RESULTS\n",
      "============================================================\n",
      "Samples processed   32\n",
      "MSE                 0.023077 ± 0.004995\n",
      "PSNR (dB)           16.48 ± 1.03\n",
      "SSIM                0.2687 ± 0.0329\n",
      "Masked MSE          0.300640\n",
      "Correlation         0.4622\n",
      "Non-zero ratio      17.0887\n",
      "Intensity ratio     1.0357\n",
      "⚠️  WARNING: Low correlation between original and reconstruction!\n",
      "============================================================\n",
      "Detailed comparison saved to: outputs/reconstruction_results/reconstruction_comparison.png\n",
      "Reconstruction data saved to: outputs/reconstruction_results/reconstructed_data.pt\n",
      "\n",
      "All results saved to: outputs/reconstruction_results\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.reconstruct --checkpoint outputs/ae.ckpt --data data/train_tensor_ds1.pt --num_samples 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/louisg/PycharmProjects/4DSTEM_AE_MSc/scripts/reconstruct.py\", line 17, in <module>\n",
      "    from models.autoencoder import Autoencoder\n",
      "ModuleNotFoundError: No module named 'models'\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.generate_embeddings --input data/train_tensor.pt --checkpoint outputs/ae.ckpt --batch_size 2048 --output outputs/embeddings.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd6c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw tensor shape: torch.Size([4788, 1, 64, 64])\n",
      "number of probe positions: 4788\n",
      "factor pairs: [(1, 4788), (2, 2394), (3, 1596), (4, 1197), (6, 798), (7, 684), (9, 532), (12, 399), (14, 342), (18, 266)] …\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "raw = torch.load(\"data/train_tensor.pt\")\n",
    "print(\"raw tensor shape:\", raw.shape)         # (N, 1, Qy, Qx)\n",
    "N = raw.shape[0]\n",
    "print(\"number of probe positions:\", N)\n",
    "\n",
    "# quick factor search\n",
    "cands = [(f, N//f) for f in range(1, int(np.sqrt(N))+1) if N % f == 0]\n",
    "print(\"factor pairs:\", cands[:10], \"…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e75c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (4788, 512, 512)\n",
      "Scan shape: (42, 114)\n",
      "Pattern shape: (512, 512)\n",
      "Loaded .dm4 file with shape: (4788, 512, 512)\n",
      "Inferred scan shape: (42, 114)\n",
      "STEM visualization saved to: outputs/stem_vis/stem_vis.png\n"
     ]
    }
   ],
   "source": [
    "!python scripts/stem_visualization.py data/Diffraction_SI.dm4 --output outputs/stem_vis/stem_vis.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ede50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from outputs/ae.ckpt\n",
      "Loading test data from data/train_tensor.pt\n",
      "Evaluating on 100 samples\n",
      "Generating reconstructions...\n",
      "Computing comprehensive metrics...\n",
      "\n",
      "============================================================\n",
      "AUTOENCODER EVALUATION SUMMARY\n",
      "============================================================\n",
      "Quality Assessment: FAIR\n",
      "Correlation: 0.8728\n",
      "Intensity Ratio: 0.1124\n",
      "Non-zero Ratio: 1.3515\n",
      "PSNR: 7.55 dB\n",
      "MSE: 0.174508\n",
      "============================================================\n",
      "Creating comprehensive visualization...\n",
      "Evaluation report saved to: outputs/eval/evaluation_report.png\n",
      "Creating STEM-specific analysis...\n",
      "STEM visualization saved to: outputs/eval/evaluation_report_stem_analysis.png\n",
      "STEM analysis saved to: outputs/eval/evaluation_report_stem_analysis.png\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.evaluate_autoencoder --checkpoint outputs/ae.ckpt --data_path data/train_tensor.pt --output_path outputs/eval/evaluation_report.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/visualization/visualise_scan_latents.py --raw workspace/proj_data_ds4_l8/inputs/train_tensor_ds4_compressed.h5 --latents workspace/proj_data_ds4_l8_with_reg/embeddings/ds4_8lat_with_regs_embeddings.pt --scan 209 194 --lat_max_cols 4 --outfig workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/latent_mosaic.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2c818",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/umap_latent_visualization.py --embeddings workspace/proj_data_ds4_l32_with_reg/dimension_reduction/umap_reduction_data.npz --output_dir workspace/proj_data_ds4_l32_with_reg/clustering --n_neighbors 50 --min_dist 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37164628",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/cluster_scan_visualization.py --umap_results \"workspace/proj_data_ds4_l32_with_reg/clustering/analysis_new/clustering_analysis_data.npz\" --raw_data \"workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5\" --output_dir \"workspace/proj_data_ds4_l32/visualisations/umap_analysis_nn_50_md_pointzero1/stem_vis_overlay\" --scan_shape 209 194 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dimension reduction with UMAP\n",
    "python scripts/analysis/dimension_reduction.py --embeddings workspace/proj_data_ds4_l32_with_reg/embeddings/ds4_32lat_with_regs_embeddings.pt --method umap --optimize_parameters --subsample 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca optimisation\n",
    "python scripts/analysis/dimension_reduction.py --embeddings workspace/proj_data_ds4_l8_with_reg/embeddings/ds4_8lat_with_regs_embeddings.pt --output_dir \"workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/pca_optimisation\" --method pca --pca_component_sweep \"3,4,5,6,7,8\" --optimize_parameters --standardize --scan_shape 209 194\n",
    "# umap optimisation\n",
    "python scripts/analysis/dimension_reduction.py --embeddings workspace/proj_data_ds4_l8_with_reg/embeddings/ds4_8lat_with_regs_embeddings.pt --output_dir \"workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/umap_optimisation\" --method umap --optimize_parameters --standardize --scan_shape 209 194\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06606931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with single component count (no optimization)\n",
    "python scripts/analysis/dimension_reduction.py --embeddings workspace/proj_data_ds4_l32_with_reg/embeddings/ds4_32lat_with_regs_embeddings.pt --output_dir workspace/proj_data_ds4_l32_with_reg/analysis_and_visualisation/pca_15_components --method pca --n_components 15 --standardize --scan_shape 209 194"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56458ce9",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # For original latent embeddings (high-dimensional)\n",
    "  python scripts/analysis/optimize_clustering.py --latent_embeddings workspace/proj_data_ds4_l32/outputs/embeddings/ds4_4epoch_embeddings.npz --output_dir \"workspace/proj_data_ds4_l32_with_reg/analysis_and_visualisation/pca_optimisation\" --max_clusters 20 --subsample 10000 --standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # For UMAP/PCA reduced embeddings  \n",
    "  python scripts/analysis/optimize_clustering.py \\\n",
    "      --reduced_data results/dimension_reduction/umap_reduction_data.npz \\\n",
    "      --output_dir results/reduced_clustering_optimization \\\n",
    "      --max_clusters 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12156703",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/clustering_analysis.py --reduced_embeddings workspace/proj_data_ds4_l32_with_reg/dimension_reduction_optimisation/umap_reduction_data.npz --output_dir workspace/proj_data_ds4_l32_with_reg/clustering/analysis --method kmeans --n_clusters 4 --standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compare multiple clustering methods for latent embeddings directly from ae\n",
    "    python scripts/analysis/clustering_analysis.py --latent_embeddings workspace/proj_data_ds4_l32/outputs/embeddings/ds4_4epoch_embeddings.npz --output_dir workspace/proj_data_ds4_l32/visualisations/latent_embeddings_cluster_analysis --method all --compare_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/optimize_clustering.py --reduced_data workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/umap_optimisation/umap_reduction_data.npz  --output_dir workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/umap_optimisation/clustering_optimisation --clusters \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering analysis on original latent embeddings k-means\n",
    "    python scripts/analysis/clustering_analysis.py --latent_embeddings workspace/proj_data_ds4_l32/outputs/embeddings/ds4_4epoch_embeddings.npz --output_dir workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/latent_clustering --method kmeans --n_clusters 3 --standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ea780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering analysis on reduced embeddings k-means\n",
    "    python scripts/analysis/clustering_analysis.py --reduced_embeddings workspace/proj_data_ds4_l32/visualisations/umap_analysis_nn_50_k_7/umap_data.npz --output_dir workspace/proj_data_ds4_l32/visualisations/clustering_analysis_umap_k_3 --method kmeans --n_clusters 3 --standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e9cca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3418114949.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython scripts/analysis/optimize_clustering.py --reduced_data workspace/proj_data_ds4_l32/visualisations/umap_analysis_nn_50_md_pointzero1/umap_data.npz  --output_dir workspace/proj_data_ds4_l32/visualisations/spectral_clustering_optimisation --max_clusters 15 --subsample 10000 --skip_kmeans --skip_hdbscan\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python scripts/analysis/optimize_clustering.py --reduced_data workspace/proj_data_ds4_l32_with_reg/analysis_and_visualisation/pca_15_components/pca_reduction_data.npz  --output_dir workspace/proj_data_ds4_l32_with_reg/analysis_and_visualisation/pca_15_components/clustering_optimisation --max_clusters 7 --subsample 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/optimize_clustering.py --umap_data workspace/proj_data_ds4_l32_with_reg/dimension_reduction_single/umap_reduction_data.npz --output_dir workspace/proj_data_ds4_l32_with_reg/clustering --max_clusters 20 --subsample 10000\n",
    "\n",
    "# latents clustering\n",
    "python scripts/analysis/optimize_clustering.py --latent_embeddings workspace/proj_data_ds4_l8_with_reg/embeddings/ds4_8lat_with_regs_embeddings.pt --output_dir workspace/proj_data_ds4_l8_with_reg/analysis_and_visualisations/latent_clustering --clusters \"3\" --standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615e0ef",
   "metadata": {},
   "source": [
    "## Overlay Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa81b39",
   "metadata": {},
   "outputs": [],
   "source": [
    " python scripts/analysis/cluster_scan_visualiza# scan, bright‑field background, every latent dim in one mosaic\n",
    "python scripts/visualization/visualise_scan_latents.py --raw workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5 --latents workspace/proj_data_ds4_l32/outputs/embeddings/ds4_4epoch_embeddings.npz --scan 194 209 --virtual bf --lat_max_cols 6 --outfig workspace/proj_data_ds4_l32/outputs/latent_mosaic.pngtion.py --umap_results workspace/proj_data_ds4_l32/visualisations/spectral_clustering_optimisation/spectral_individual_results/spectral_3/cluster_info_spectral_3_clus.json --scan_shape 209 194 --output_dir workspace/proj_data_ds4_l32/visualisations/spectral_clustering_optimisation/stem_vis_overlay --raw_data workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/cluster_scan_visualization.py --clustered_data workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/cluster_labels.npy  --scan_shape 209 194 --output_dir workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/stem_vis_overlay --raw_data workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/umap_latent_visualization.py \\\n",
    "        --embeddings embeddings/patterns_embeddings.npz \\\n",
    "        --output_dir results/umap_analysis \\\n",
    "        --n_neighbors 50 \\\n",
    "        --min_dist 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5565a",
   "metadata": {},
   "source": [
    "## Polar Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/latent_cluster_polar_map.py --data workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5 --dset patterns --labels workspace/proj_data_ds4_l32/visualisations/umap_analysis_nn_50_k_7/umap_data.npz --scan-shape 209 194 --config workspace/proj_data_ds4_l32/visualisations/polar_map_improved/improved_polar_config.yaml --out workspace/proj_data_ds4_l32/visualisations/polar_map_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "python scripts/analysis/latent_cluster_polar_map.py --data workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5 --dset patterns --labels workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/cluster_labels.npy --scan-shape 209 194 --config workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/polar_map/polar_config.yaml --out workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/polar_map --interactive-ks\n",
    "pace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "python scripts/analysis/latent_cluster_polar_map.py --data workspace/proj_data_ds4_l32/inputs/train_tensor_ds4_compressed.h5 --dset patterns --labels workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/cluster_labels.npy --scan-shape 209 194 --config workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/polar_map/polar_config.yaml --out workspace/proj_data_ds4_l8/analysis_and_visualisations/umap_optimisation/clustering_3/spectral_individual_results/spectral_3/polar_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m scripts.visualization.diagrams.visualize_with_torchlens --model models.autoencoder:Autoencoder --scan-y 209 --scan-x 194 --det 256 --latent-dim 32 --out torchlens_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ef23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control nesting depths and which blocks to show:\n",
    "  python -m scripts.visualization.diagrams.visualize_with_torchlens --model models.autoencoder:Autoencoder --blocks-depth 1 --inside-depth 4 --focus-modules encoder.resnet1,decoder.resnet_up1 --out torchlens_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c15ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot -Tsvg workspace/diagrams/landscape/torchlens_final_inside_decoder_decoder_resnet_up1_clean_landscape.dot -o torchlens_final_inside_decoder_decoder_resnet_up1_clean_landscape.svg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
